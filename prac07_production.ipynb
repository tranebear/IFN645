{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 6: Machine Learning Model in Production\n",
    "\n",
    "### In this practical note\n",
    "1. [Academic vs industry](#difference)\n",
    "2. [Data pipeline](#pipeline)\n",
    "3. [Retraining](#retrain)\n",
    "4. [Scaling](#scale)\n",
    "---\n",
    "\n",
    "### Important Changelog:\n",
    "* (02/11/2017) Large updates. Set notes to beta.\n",
    "\n",
    "The practical note for this week introduces you to the practical aspect of Python machine learning models in production environment. There are major differences in focus between models in academic/scientific settings compared to models in industry/production settings. This topic is a seldom one to discuss in an university unit, but I believe it is equally as important as other theoretical components.\n",
    "\n",
    "To ensure sufficient time to finish your workload, anything discussed in this week will not be graded unit components (assignment/exam).\n",
    "\n",
    "**This tutorial notes is in beta version. Please give us feedbacks and suggestions on how to make it better. Ask your tutor for any question and clarification.**\n",
    "\n",
    "## 1. Academic vs industry\n",
    "\n",
    "As we mentioned early in this unit, any data mining projects should provide values to the stakeholders. This requirement brings about the deployement of models in production systems.\n",
    "\n",
    "Differences are:\n",
    "\n",
    "### 1.1. Metrics and performance\n",
    "\n",
    "In academic world, raw performance in objective functions is everything. Better accuracy/precision/recall/F1.\n",
    "\n",
    "In industry, business-driven metrics are more important. Faster models are important too. Does not matter if your model is good, but it is slow AF.\n",
    "\n",
    "### 1.2. Complexity vs interpretability\n",
    "\n",
    "In academic setting, more complex models are not a problem.\n",
    "\n",
    "Understanding why a certain model is classified as such is important in industry.\n",
    "\n",
    "### 1.3. Treat it as a system\n",
    "\n",
    "Unit test, software engineering stuffs.\n",
    "\n",
    "\n",
    "## 2. Data pipeline\n",
    "\n",
    "Wrap many important things into a single unit. Ensure things does not change and is consistent.\n",
    "\n",
    "Serialisation? How to do it? Pickle?\n",
    "\n",
    "\n",
    "## 3. Retraining\n",
    "\n",
    "Models need to be retrained to be up to date. User behaviour changes all the time.\n",
    "\n",
    "\n",
    "\n",
    "### 3.1. When to retrain\n",
    "\n",
    "Monthly? Yearly?\n",
    "\n",
    "### 3.2. Online training\n",
    "\n",
    "Atomic based training.\n",
    "\n",
    "\n",
    "## 4. Scaling\n",
    "\n",
    "Okay, let's say that you have mastered the art of deploying your `sklearn`-based model into production systems. You have built a great API with fast data pipeline. Your business is flourishing thanks to your revolutionary model.\n",
    "\n",
    "Unfortunately, growing business brings a problem to your machine learning model. There are now a lot of requests to that API and response time is getting slower. How do we scale machine learning models? Below I have listed a number of tricks that you could use.\n",
    "\n",
    "### 4.1. Batch prediction\n",
    "\n",
    "In many production systems, real-time atomic predictions is not required. Often prediction tasks can be stashed and delayed to be then processed in batch basis. Batch processing allows the model to take advantage of vectorised computations and SIMD instructions (single instruction, multiple data), which speeds up computational performance significantly.\n",
    "\n",
    "To refer a real-life example, GoCardless, a YCombinator funded startup which focuses on cashless payments, uses machine learning models to perform fraud detection activities. Most payment transactions in the company take 1-2 days, therefore, batch prediction is very suitable for their business case. In the end, the fraud detection is run a nightly-cron job (every 24 hours).\n",
    "\n",
    "### 4.2. Horisontal scaling\n",
    "\n",
    "Horisontal scaling refers to the process of accomodating growing volume of computing tasks by spreading it over large number of commodity hardware. Can be for ML models (self contained, stateless).\n",
    "\n",
    "### 4.3. Moving to scalable platforms\n",
    "\n",
    "Hadoop or Spark. ML libraries are there.\n",
    "\n",
    "[Auto-scaling scikit-learn with Spark](https://databricks.com/blog/2016/02/08/auto-scaling-scikit-learn-with-apache-spark.html)\n",
    "\n",
    "# End Notes\n",
    "\n",
    "Interested more? More resources on these stuffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
